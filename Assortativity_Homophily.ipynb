{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx.drawing\n",
    "\n",
    "def homophily_oneset(graph,vertices):\n",
    "    l=len(vertices)\n",
    "    if (l<1):\n",
    "        return -1\n",
    "    h=0.0\n",
    "    g2=nx.to_dict_of_lists(graph)\n",
    "    for x in vertices:\n",
    "        for ver in g2[x]:\n",
    "            if ver in vertices:\n",
    "                h+=1.0\n",
    "                #print (x,ver,h)\n",
    "    return h/(2.0*l)\n",
    "def homophily_avg(graph,focals):\n",
    "    avgh=0.0\n",
    "    c=0.0\n",
    "    #print(len(focals))\n",
    "    for group in focals:\n",
    "        x=homophily_oneset(graph,focals[group])\n",
    "        if x>=0:\n",
    "            avgh+=x\n",
    "            c+=1.0\n",
    "    return avgh/c\n",
    "\n",
    "\n",
    "def clustering(graph,vertex):\n",
    "    \"\"\" finds clustering coefficient of vertex\n",
    "        in graph from the set of vertices provided\n",
    "    \"\"\"\n",
    "    k=graph.degree[vertex]\n",
    "    if k>1:\n",
    "        c=0.0\n",
    "        for w in graph.neighbors(vertex+1):\n",
    "            for x in graph.neighbors(vertex+1):\n",
    "                if (x in graph.neighbors(w)) and x!=w:\n",
    "                    c=c+1.0\n",
    "        c=c/2\n",
    "        return ((2*c)/(k*(k-1)))\n",
    "    return 0\n",
    "\n",
    "def focal_structures(graph):\n",
    "    \"\"\" finds focal_structures in graph based on clustering coefficients\n",
    "        if clustering coefficients of two vertices are more than the\n",
    "        average clustering coefficient and they are adjacent, the two verticesa\n",
    "        are included in the same focal structure\n",
    "    \"\"\"\n",
    "    s=0\n",
    "    p=0\n",
    "    dictt={}\n",
    "    c_co=[]\n",
    "    ver=sorted(list(graph.nodes))\n",
    "    for x in range(len(ver)):       #get clustering coefficient for each vertex\n",
    "        dictt[x]=[]\n",
    "        c_co.append(clustering(graph,ver[x]))\n",
    "        s=s+c_co[x]\n",
    "    avg=(s/len(graph))\n",
    "    visited=[]\n",
    "    for i in range(len(ver)):\n",
    "        visited.append(0)\n",
    "    for i in range(len(ver)):\n",
    "        f=-1\n",
    "        for x in range(len(ver)):\n",
    "            for y in range(len(dictt[x])):\n",
    "                if dictt[x][y]==ver[i]:\n",
    "                    f=x\n",
    "                    break\n",
    "            if f>-1:\n",
    "                break\n",
    "        if f==-1:\n",
    "            dictt[p].append(ver[i])\n",
    "            f=p\n",
    "            p=p+1\n",
    "        for x in range(i+1,len(ver)):    #cluster vertices based on clustering coefficient\n",
    "            if visited[x]==0 and (ver[x]+1 in graph.neighbors(ver[i]+1)) and ((c_co[i] > avg and c_co[x] > avg) or (c_co[i] < avg and c_co[x] < avg)):\n",
    "                dictt[f].append(ver[x])\n",
    "                visited[x]=1\n",
    "    for i in range(len(ver)):\n",
    "        dictt[i]=list(set(dictt[i]))\n",
    "    return dictt\n",
    "\n",
    "def graph_create_dataset(graph_no):\n",
    "    graph=[[]for i in range(graph_no)]\n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/facebook.txt\") as fp1:  \n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp1:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "            \n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/hamster.txt\") as fp2:\n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp2:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "            \n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/hamster_full.txt\") as fp3:\n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp3:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "    \n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/google_plus.txt\") as fp4:\n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp4:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "    \n",
    "    with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/twitter.txt\") as fp5:\n",
    "        graph[0]=nx.Graph()\n",
    "        for line in fp5:\n",
    "            temp=line.split(\" \")\n",
    "            x=int(temp[0])\n",
    "            y=int((temp[1].split(\"\\n\"))[0])\n",
    "            graph[0].add_edges_from([(x,y)])\n",
    "            \n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/brightkite.txt\") as fp6:  \n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp6:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "            \n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/Epinions.txt\") as fp7:\n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp7:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "            \n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/facebook_wosn.txt\") as fp8:\n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp8:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "\n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/slashdot.txt\") as fp9:\n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp9:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "            \n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/dataset/advogato.txt\") as fp10:    \n",
    "#         graph[0]=nx.Graph()\n",
    "#         for line in fp10:\n",
    "#             temp=line.split(\" \")\n",
    "#             x=int(temp[0])\n",
    "#             y=int((temp[1].split(\"\\n\"))[0])\n",
    "#             graph[0].add_edges_from([(x,y)])\n",
    "            \n",
    "    return(graph)\n",
    "           \n",
    "\n",
    "if __name__=='__main__':\n",
    "    graph_no=1\n",
    "    graph=[[]for i in range(graph_no)]\n",
    "    graph=graph_create_dataset(graph_no)\n",
    "\n",
    "    ################### ASSORTATIVITY  ##############################\n",
    "#     with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/Assortativity_homophily.odt\",\"a+\") as sn:\n",
    "#         sn.write(\"\\n\")\n",
    "#         sn.write(\" ASSORTATIVITY OF THE NETWORKS CONSIDERED ---------\")\n",
    "#         sn.write(\"\\n\\n\")\n",
    "#         for i in range(graph_no):\n",
    "#             corr_coeff=nx.degree_pearson_correlation_coefficient(graph[i])                         \n",
    "#             sn.write(\"Assortativity of Graph \"+str(i+1)+\" : \"+str(corr_coeff))\n",
    "#             sn.write(\"\\n\")\n",
    "            \n",
    "    ####################### HOMOPHILY ##################################\n",
    "    with open(\"/home/sukanya/Desktop/jadavpur_internship/CODES/Assortativity_homophily.odt\",\"a+\") as sn:\n",
    "        sn.write(\"\\n\")\n",
    "#         sn.write(\" HOMOPHILY OF THE NETWORKS CONSIDERED ---------\")\n",
    "#         sn.write(\"\\n\\n\")\n",
    "        for i in range(graph_no):\n",
    "            focal_struct=focal_structures(graph[i])\n",
    "#             print(focal_struct)\n",
    "            homophily=homophily_avg(graph[i],focal_struct)\n",
    "            sn.write(\"Homophily of Graph \"+str(i+1)+\" : \"+str(homophily))\n",
    "            sn.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
